---
layout: post
title: "Detection of exudates in fundus photographs with imbalanced learning using conditional generative adversarial network"
background: #white grey deepgrey blue purple green yellow red orange
background-image: https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1537808948967&di=51b59730f691a8663de2e2f936dcf4ac&imgtype=0&src=http%3A%2F%2Fimg5.duitang.com%2Fuploads%2Fitem%2F201405%2F31%2F20140531174123_zCPNY.thumb.700_0.jpeg
categories:
- 论文
- 深度学习
tags:
- 图像分割
- OCT
author: Dimension
description: 这篇论文使用了条件生成对抗网络(cGAN)实现了数据增强，并对图像中较小的分泌物(少数类)进行了上采样，使用修改后的Unet即MU-net对图像进行分割
mermaid: true
date: 2018-09-24 22:20:21
ico: #book game note chat code image web link design lock
---

* 目录   
{:toc #markdown-toc}

## 简介
糖尿病视网膜病变(DR)是世界范围内致盲的主要原因。然而，如果及早诊断和干预，90%的DR致盲是可以预防的。视网膜渗出物可在DR早期观察到，可作为早期DR诊断的标志。深卷积神经网络(Deep tional neural network, DCNNs)已被应用于渗出检测，取得了良好的效果。然而，在使用基于DCNN的方法进行渗出检测时，存在两个主要的挑战。一个是来自医学专家的标记数据数量非常有限，另一个是不同类别数据分布严重不平衡。首先，正常眼睛的图像比有分泌物的眼睛多很多，特别是对于筛选数据集。其次，在含有渗出物的图像中，正常象素(非渗出物)的数目远大于异常象素(渗出物)的数目。针对小样本集问题，提出了一种基于U-net结构的集成卷积神经网络。为了缓解数据不平衡的问题，采用条件生成对抗性网络(cGAN)生成保留标签的少数类数据，实现数据的增强。该网络在一个数据集(e_ophtha_EX)上进行训练，并在其他三个公共数据集(DiaReTDB1、HEI-MED和MESSIDOR)上进行测试。CGAN作为一种数据增强方法，显著提高了网络的鲁棒性和泛化特性，在病灶水平分别测量f1值为92.79%、92.46%、91.27%和94.34%。而没有cGAN的f1得分分别为92.66%、91.41%、90.72%和90.58%。在图像水平测量时，cGAN的准确率分别为95.45%、92.13%、88.76%和89.58%，而cGAN的准确率分别为86.36%、87.64%、76.33%和86.42%。根据世界卫生组织2016年的报告，从1980年到2014年，全球糖尿病患病率从4.7%上升到8.5%，成年人糖尿病患病率从1.08亿上升到4.22亿。在糖尿病引起的许多并发症中，糖尿病视网膜病变(DR)是致盲的重要原因。2010年，DR导致2.6%失明。DR是视网膜小血管长期累积损伤的结果。20年的糖尿病后，几乎所有的I型糖尿病患者和大于60%的II型糖尿病患者有一定程度的视网膜病变。在DR的早期，患者可能没有任何视力问题的症状。然而，当它发展到晚期，它可能会永久地导致视力丧失和失明。因此，糖尿病患者有一个全面的视网膜是很重要的每年至少检查一次。结果表明，在90%的病例中，由DR引起的失明是可以预防的 通过常规筛查，早期发现病例。眼底摄影是糖尿病视网膜病变最常用和最有效的筛查方法。眼科医生寻找DR的早期症状，如渗出物。渗出物是在视网膜内毛细血管渗漏处出现的脂质和脂蛋白沉积。它们在DR早期发育，可能以黄色区域出现，大小不一，从几个像素到视盘大小不等(图1)。眼底图像通常由眼科医生检查。然而，由于眼科医生数量有限，筛查人群众多，许多计算机辅助诊断系统(CAD)已经被开发出来，可以自动检测DR的典型病理征象希望提高筛查效率，释放昂贵的医疗资源。的 CADs的敏感性和准确性是早期诊断的关键。然而，DR早期的低对比度、不规则形状和稀疏性给分析方法带来了巨大的挑战。

![这里是图片](/wsc12358.github.io/assets/images/2018-09-24/1.png)

深度卷积神经网络已经被证明在许多方面优于传统的图像分析方法，特别是因为它们不需要显式特征提取。近年来，采用深度学习的方法检测彩色眼底照片中的渗出物，虽然报道的最高灵敏度和准确率仍然低于目前最先进的传统图像分析方法，但仍显示出良好的效果。例如，[5]的深度学习方法对DIARETDB1数据集[9]的灵敏度最高为81.35%，而[8]的常规方法对DIARETDB1数据集[9]的灵敏度均为92.42%。深度学习方法的表现主要受到两大挑战的制约。一类是训练网络中有限的专家标记训练数据，另一类是不同类别的严重不平衡表示。在医学图像分析领域，由于获取地面真实数据的成本较高，专家标记数据有限是一个普遍存在的问题。不平衡数据集表现在两个方面。一是病理状态的图像比正常状态的要少得多。对于在大规模筛选过程中获得的数据集，如DR筛选，尤其如此。在这些数据集中，大多数图像不包含任何病理条件。不平衡数据的另一个方面是异常像素的数量远远少于正常像素的数量。例如，在只有少量渗出物的图像中，98%以上的像素是正常的，2%左右的像素是异常的。不同类的这种严重的不平衡表示给构建具有良好泛化特性的鲁棒可靠神经网络带来了很大的挑战。

针对以上问题，我们开发了基于U-net框架的集成深度卷积神经网络(MU-net)。此外，为了解决不平衡类问题，我们使用条件生成对抗性网络(cGAN)来扩充数据集，并特别对少数类进行了抽样。我们的方法明显优于以往的方法，对不同的数据集具有良好的泛化特性。

## 方法
在本节中，我们提出了用于渗出检测的改进的U-net (MU-Net)结构，并演示了将条件生成对抗性网络(cGAN)用于生成合成图像作为一种新的数据增强和少数类upsampling方法。

### 1 图像预处理
利用不同类型的眼底摄像机采集不同数据集的图像，得到不同分辨率和信噪比(SNR)的图像。为了减少来自不同数据集的图像变化，我们在将图像输入神经网络之前应用了预处理步骤。首先，所有的图像被调整到580 580像素。其次，只对原始RGB图像中的绿色通道进行了处理，因为绿色通道对背景[31]中渗出物的对比度最高。然而，对于GAN训练，我们使用的是原始的RGB图像。第三，应用自适应增强技术[32]提高视网膜表面渗出物的对比度。

### 2 Unet和MU-net
U-net最早由Ronneberger[33]提出用于生物医学图像分割。它是一种基于卷积神经网络的监督方法。它的设计目的是产生精确的分割与少量的训练图像，这是特别重要的医疗图像应用，因为它通常是昂贵的标签大量的医疗图像医学专家。

![这里是图片](/wsc12358.github.io/assets/images/2018-09-24/2.png)

以下是Unet和MU-net的结构细节


![这里是图片](/wsc12358.github.io/assets/images/2018-09-24/3.png)

两个卷积层都有一个3×3核，然后是标准化和dropout。激活函数采用LeakyReLU.

![这里是图片](/wsc12358.github.io/assets/images/2018-09-24/4.png)

四个MU-net模块在卷积核大小上不同(3 3 4 4 5 5 6)(图6)。2(c))。

GANs是[35 39]中提出的生成对抗网络。在非条件GAN中，生成器G被训练成从随机噪声向量z映射到输出向量y: G: z !在条件GANs (cGAN)[39]中，除了随机噪声向量z外，还提供了一个观测图像x作为输入。CGANs学习从观察到的图像x和随机噪声向量z到y: G: fx的映射;zg !通过优化下面的目标函数.

![这里是图片](/wsc12358.github.io/assets/images/2018-09-24/5.png)

![这里是图片](/wsc12358.github.io/assets/images/2018-09-24/6.png)

我们采用了[39]中pix2pix中的cGAN体系结构。pix2pix框架的两个关键特性是基于U-net[33]的生成器和一个马尔可夫鉴别器(PatchGAN)。基于U-net的生成器允许低级图像信息在网络上快捷地实现更逼真的图像。在训练阶段,pix2pix网络的输入图像的原始RGB图像与相应的二进制地面实况图像训练集的e_ophtha_EX(图3)。pix2pix的训练集是一样的训练集的U-net MU-net块和MU-net。所有的权值都是从均值0和标准差0.02的高斯分布中初始化的。为了优化网络，我们在鉴别器D上交替使用梯度下降步，然后在发生器G[39]上交替使用梯度下降步。我们应用了亚当的能手[40],学习速率为0.0002,和动量参数β1 = 0:5;β2 = 0:999。

pix2pix网络训练了350个epoch，批大小为1。在图像生成阶段，pix2pix网络的输入是训练集中的二值地面真值图像，输出是与网络输入相似但不同的合成图像。我们将经过训练的pix2pix网络应用于e_ophtha_EX数据集中的所有60张二进制地面真实图像，生成了60张合成图像。然后我们独立地训练了第二次pix2pix，没有使用第一次训练的重量。之后，通过第二次训练pix2pix，我们又生成了60张合成图像。在分泌物的外观和外观上，大多数合成图像与真实图像非常相似，但也有一些人工痕迹明显，如图4所示。这与之前的研究一致，一些GAN生成的图像与真实图像相差甚远，这在以前被认为是GAN[39]的一个普遍问题。总共生成了120幅合成图像，其中选择了86幅无伪图像。

![这里是图片](/wsc12358.github.io/assets/images/2018-09-24/7.png)



